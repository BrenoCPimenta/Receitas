{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe_links = []\n",
    "# for page_i in tqdm(range(1,100+1)):\n",
    "#     if page_i % 5 == 0:\n",
    "#         time.sleep(1)\n",
    "#     r = requests.get('https://www.tudogostoso.com.br/receitas?page='+str(page_i))\n",
    "#     soup = BeautifulSoup(r.text, 'html.parser')\n",
    "#     page_recipes = soup.find_all('a', class_='link row m-0')\n",
    "#     for link in page_recipes:\n",
    "#         recipe_links = recipe_links + link.get_attribute_list('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe_links_file = open('recipe_links.json','w')\n",
    "# recipe_links_file.write(json.dumps(recipe_links))\n",
    "\n",
    "f = open('../data/recipe_links.json')\n",
    "recipe_links = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages = pd.DataFrame()\n",
    "# for page_i in tqdm(range(len(recipe_links))):\n",
    "#     if page_i == 100:\n",
    "#         break\n",
    "#     link = recipe_links[page_i]\n",
    "#     page_link = 'https://www.tudogostoso.com.br'+link\n",
    "#     r = requests.get(page_link)\n",
    "#     pages = pages.append({\n",
    "#         'link': page_link,\n",
    "#         'raw_text': r.text\n",
    "#     }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages.to_csv('pages_test.csv', index=False)\n",
    "pages = pd.read_csv('../data/pages_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:10,  9.63it/s]\n"
     ]
    }
   ],
   "source": [
    "pages['ingredients'] = np.nan\n",
    "pages['ingredients'] = pages['ingredients'].astype('object')\n",
    "\n",
    "for row in tqdm(pages.itertuples()):\n",
    "    soup = BeautifulSoup(row.raw_text, 'html.parser')\n",
    "    page_ingredients = soup.find_all('span', class_='p-ingredient')\n",
    "    \n",
    "    ingredients = []\n",
    "    for ingredient in page_ingredients:\n",
    "        ingredient_text = ingredient.get_text()\n",
    "        ingredient_text = ingredient_text.replace('\\xa0','')\n",
    "        if len(ingredient_text) > 0:\n",
    "            ingredients.append(ingredient_text)\n",
    "    pages.at[row.Index,'ingredients'] = ingredients\n",
    "\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    page_title = soup.find_all('title')[0].get_text().replace('\\n','')\n",
    "    title = [sent for sent in soup.find_all('div', class_='recipe-title')[0].get_text().split('\\n') if len(sent)>1 ][0]\n",
    "\n",
    "    datetime = soup.find_all('time', class_='dt-duration')[0]['datetime']\n",
    "    time = ' '.join([sent for sent in soup.find_all('time', class_='dt-duration')[0].get_text().split('\\n') if len(sent)>0 ])\n",
    "\n",
    "    portions = soup.find_all('data', class_='p-yield num yield')[0]['value']\n",
    "    favorites = soup.find_all('data', class_='num')[1].get_text().replace('\\n','')\n",
    "    coments = soup.find_all('data', class_='num')[2].get_text().replace('\\n','')\n",
    "    \n",
    "    group = soup.find_all('ol', class_='breadcrumb')[0].find_all('span')[2].get_text().replace('\\n','')\n",
    "\n",
    "    images = [img['src'] for img in soup.find_all('img', class_='pic') ]\n",
    "    \n",
    "    pages.at[row.Index,'text'] = text\n",
    "    pages.at[row.Index,'page_title'] = page_title\n",
    "    pages.at[row.Index,'title'] = title\n",
    "    pages.at[row.Index,'datetime'] = datetime\n",
    "    pages.at[row.Index,'time'] = time\n",
    "    pages.at[row.Index,'portions'] = portions\n",
    "    pages.at[row.Index,'favorites'] = favorites\n",
    "    pages.at[row.Index,'coments'] = coments\n",
    "    pages.at[row.Index,'group'] = group\n",
    "    pages.at[row.Index,'images'] = images\n",
    "    \n",
    "    \n",
    "    \n",
    "# serie = ingredients_df.ingredient.str.replace('[^A-z+\\s\\u00C0-\\u00FF]','')\n",
    "# serie = serie.str.lower()\n",
    "# serie = serie.str.split(' ').apply(lambda x: [i for i in x if len(i)>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages.to_csv('data/recipes_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
